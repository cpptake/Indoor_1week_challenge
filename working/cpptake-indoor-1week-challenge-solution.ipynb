{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Indoorコンペ　1週間チャレンジ\n\n<br>Indoorコンペに1週間限定で参加し、銅メダルを獲得した解法を残します。\n<br>コンペ詳細はこちら。https://www.kaggle.com/c/indoor-location-navigation\n\n## PipeLine\n\n1. アンサンブル\n<br>LB最高スコアのアンサンブルと、MultiOutputMLPのアンサンブルが最もscoreが高かったため採用\n<br>以降の処理は、アンサンブルの結果に対して後処理をするパートとなる。\n\n2. device id Leak\n<br>アンサンブルの結果に対してdevice id leakegeを適用。参照先は下記のURL。\n<br>https://www.kaggle.com/iwatatakuya/use-leakage-considering-device-id-postprocess\n\n3. Snap to grid\n<br>上記の結果に対して、snap to gridを適用。（閾値を外れている推定位置を最近傍のGridに移動させる。）参照先は下記のURL。\n<br>https://www.kaggle.com/robikscube/indoor-navigation-snap-to-grid-post-processing\n\n","metadata":{}},{"cell_type":"markdown","source":"# アンサンブルパート","metadata":{}},{"cell_type":"code","source":"import multiprocessing\nimport numpy as np\nimport pandas as pd\nimport scipy.interpolate\nimport scipy.sparse\nfrom tqdm import tqdm\n\nimport json\nimport re\nimport gc\nimport pickle\nimport itertools\nimport pandas as pd\nimport numpy as np\nfrom glob import glob\nfrom datetime import datetime as dt\nfrom pathlib import Path\nfrom tqdm import tqdm\nimport datetime\n\n# from indoor_location_competition_20.io_f import read_data_file\n# import indoor_location_competition_20.compute_f as compute_f\n\nfrom dataclasses import dataclass\n\nimport warnings # Supress warnings \nwarnings.filterwarnings('ignore')\nfrom matplotlib import pyplot as plt\n\nfrom tqdm.notebook import tqdm\n\nimport json\nfrom datetime import datetime\nfrom glob import glob","metadata":{"execution":{"iopub.status.busy":"2021-05-29T15:00:16.922711Z","iopub.execute_input":"2021-05-29T15:00:16.923325Z","iopub.status.idle":"2021-05-29T15:00:17.303806Z","shell.execute_reply.started":"2021-05-29T15:00:16.923194Z","shell.execute_reply":"2021-05-29T15:00:17.302876Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"\nexp1 = pd.read_csv('../input/indoor-emsemble/exp1_multioutput_mlp.csv')\nexp2 = pd.read_csv('../input/indoor-emsemble/exp2_Cost_Minim.csv').drop('index',axis = 1)\nexp3 = pd.read_csv('../input/indoor-emsemble/exp3 use_leakage_considering.csv')\nexp4 = pd.read_csv('../input/indoor-emsemble/exp2_Cost_Minim.csv').drop('index',axis = 1)\nexp5 = pd.read_csv('../input/indoor-emsemble/exp5_ensemble.csv')\n\nLB4555 = pd.read_csv('../input/lb4555/submission.csv')\nLB4522 = pd.read_csv('../input/lb4522/submission.csv')\nLB4722 = pd.read_csv('../input/lb4722/submission.csv')\nLB4470 = pd.read_csv('../input/indoor-loc-and-nav-subs/submission_4470.csv')\nLB4470emsemble = pd.read_csv('../input/indoor-emsemble/LB4470_0.95exp2_0.05.csv')\nLB4483 = pd.read_csv('../input/indoor-loc-and-nav-subs/submission_4_483.csv')\n\nleak_4555 = pd.read_csv('../input/indoor-emsemble/submission_df_leak_end_LB4555.csv')\nleak_4556 = pd.read_csv('../input/indoor-emsemble/submission_df_leak_start_LB4556.csv')\nleak_4725 = pd.read_csv('../input/indoor-emsemble/submission_df_leak_all_LB4725.csv')\n","metadata":{"execution":{"iopub.status.busy":"2021-05-29T15:11:56.553365Z","iopub.execute_input":"2021-05-29T15:11:56.553741Z","iopub.status.idle":"2021-05-29T15:11:56.809668Z","shell.execute_reply.started":"2021-05-29T15:11:56.553712Z","shell.execute_reply":"2021-05-29T15:11:56.808825Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"df = pd.merge(exp2,leak_4555,how = 'inner', on = 'site_path_timestamp')\ndf = df.merge(LB4522,how = 'inner' ,on = 'site_path_timestamp')\n\ncol_dict = {'x_x':'sub0_x',\n          'y_x':'sub0_y',\n          'x_y':'sub1_x',\n          'y_y':'sub1_y',\n          'x':'sub2_x',\n          'y':'sub2_y',\n          }\ndf = df.rename(columns=col_dict)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T15:12:34.788340Z","iopub.execute_input":"2021-05-29T15:12:34.788729Z","iopub.status.idle":"2021-05-29T15:12:34.826077Z","shell.execute_reply.started":"2021-05-29T15:12:34.788693Z","shell.execute_reply":"2021-05-29T15:12:34.825284Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"\n# # ver12\ndf_emsemble = pd.DataFrame(LB4522)\n\nLB4470 = LB4470.set_index('site_path_timestamp')\nexp2 = exp2.set_index('site_path_timestamp')\n\ndf_emsemble['x'] = 0.8*LB4470['x'].values + 0.2*exp2.loc[LB4470.index, 'x'].values\ndf_emsemble['y'] = 0.8*LB4470['y'].values + 0.2*exp2.loc[LB4470.index, 'y'].values\n\n\n# # # ver11\n# # df = LB4522.copy\n# LB4470 = LB4470.set_index('site_path_timestamp')\n# exp2 = exp2.set_index('site_path_timestamp')\n\n# LB4470['x'] = 0.85*LB4470['x'].values + 0.15*exp2.loc[LB4470.index, 'x'].values\n# LB4470['y'] = 0.85*LB4470['y'].values + 0.15*exp2.loc[LB4470.index, 'y'].values\n\n\n# # # ver11\n# # df = LB4522.copy\n# LB4470 = LB4470.set_index('site_path_timestamp')\n# exp2 = exp2.set_index('site_path_timestamp')\n\n# LB4470['x'] = 0.9*LB4470['x'].values + 0.1*exp2.loc[LB4470.index, 'x'].values\n# LB4470['y'] = 0.9*LB4470['y'].values + 0.1*exp2.loc[LB4470.index, 'y'].values\n\n\n\n# # # ver11\n# # df = LB4522.copy\n# LB4470 = LB4470.set_index('site_path_timestamp')\n# exp2 = exp2.set_index('site_path_timestamp')\n\n# LB4470['x'] = 0.95*LB4470['x'].values + 0.05*exp2.loc[LB4470.index, 'x'].values\n# LB4470['y'] = 0.95*LB4470['y'].values + 0.05*exp2.loc[LB4470.index, 'y'].values\n\n# # # ver9\n# # df = LB4522.copy\n# LB4470 = LB4470.set_index('site_path_timestamp')\n# LB4483 = LB4483.set_index('site_path_timestamp')\n\n# LB4522 = LB4522.set_index('site_path_timestamp')\n# LB4555 = LB4555.set_index('site_path_timestamp')\n# exp4 = exp4.set_index('site_path_timestamp')\n\n# #ver10\n# LB4470['x'] = 0.7*LB4470['x'].values + 0.3*LB4483.loc[LB4470.index, 'x'].values\n# LB4470['y'] = 0.7*LB4470['y'].values + 0.3*LB4483.loc[LB4470.index, 'y'].values\n\n# # ver9 \n# LB4522['x'] = 0.4*LB4522['x'].values + 0.4*LB4555.loc[LB4522.index, 'x'].values + 0.2*exp4.loc[LB4522.index, 'x'].values\n# LB4522['y'] = 0.4*LB4522['y'].values + 0.4*LB4555.loc[LB4522.index, 'y'].values + 0.2*exp4.loc[LB4522.index,'y'].values\n\n# # # ver8\n# df['x'] = df['sub0_x']*0.4 + df['sub1_x']*0.3 + df['sub2_x']*0.3\n# df['y'] = df['sub0_y']*0.4 + df['sub1_y']*0.3 + df['sub2_y']*0.3\n\n\n# # ver7\n# df['x'] = df['sub1_x']*0.4 + df['sub2_x']*0.6\n# df['y'] = df['sub1_y']*0.4 + df['sub2_y']*0.6\n\n# # exp6\n# df['x'] = df['sub0_x']*0.4 + df['sub1_x']*0.3 + df['sub2_x']*0.3\n# df['y'] = df['sub0_y']*0.4 + df['sub1_y']*0.3 + df['sub2_y']*0.3","metadata":{"execution":{"iopub.status.busy":"2021-05-29T15:12:41.957545Z","iopub.execute_input":"2021-05-29T15:12:41.958185Z","iopub.status.idle":"2021-05-29T15:12:41.981586Z","shell.execute_reply.started":"2021-05-29T15:12:41.958149Z","shell.execute_reply":"2021-05-29T15:12:41.980638Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"df_emsemble","metadata":{"execution":{"iopub.status.busy":"2021-05-29T15:12:47.447789Z","iopub.execute_input":"2021-05-29T15:12:47.448145Z","iopub.status.idle":"2021-05-29T15:12:47.464353Z","shell.execute_reply.started":"2021-05-29T15:12:47.448114Z","shell.execute_reply":"2021-05-29T15:12:47.462885Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"                                     site_path_timestamp  floor           x  \\\n0      5a0546857ecc773753327266_046cfa46be49fc1083481...      0   93.213821   \n1      5a0546857ecc773753327266_046cfa46be49fc1083481...      0   83.239300   \n2      5a0546857ecc773753327266_046cfa46be49fc1083481...      0   84.942722   \n3      5a0546857ecc773753327266_046cfa46be49fc1083481...      0   86.081008   \n4      5a0546857ecc773753327266_046cfa46be49fc1083481...      0   87.944170   \n...                                                  ...    ...         ...   \n10128  5dc8cea7659e181adb076a3f_fd64de8c4a2fc5ebb0e9f...      5  208.630347   \n10129  5dc8cea7659e181adb076a3f_fd64de8c4a2fc5ebb0e9f...      5  206.774168   \n10130  5dc8cea7659e181adb076a3f_fd64de8c4a2fc5ebb0e9f...      5  204.091932   \n10131  5dc8cea7659e181adb076a3f_fd64de8c4a2fc5ebb0e9f...      5  196.018451   \n10132  5dc8cea7659e181adb076a3f_fd64de8c4a2fc5ebb0e9f...      5  193.621249   \n\n                y  \n0       96.479153  \n1       99.883803  \n2      105.075408  \n3      109.093861  \n4      112.365452  \n...           ...  \n10128  101.163545  \n10129  103.814537  \n10130  110.622288  \n10131  116.925300  \n10132  120.127632  \n\n[10133 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>site_path_timestamp</th>\n      <th>floor</th>\n      <th>x</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5a0546857ecc773753327266_046cfa46be49fc1083481...</td>\n      <td>0</td>\n      <td>93.213821</td>\n      <td>96.479153</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5a0546857ecc773753327266_046cfa46be49fc1083481...</td>\n      <td>0</td>\n      <td>83.239300</td>\n      <td>99.883803</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5a0546857ecc773753327266_046cfa46be49fc1083481...</td>\n      <td>0</td>\n      <td>84.942722</td>\n      <td>105.075408</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5a0546857ecc773753327266_046cfa46be49fc1083481...</td>\n      <td>0</td>\n      <td>86.081008</td>\n      <td>109.093861</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5a0546857ecc773753327266_046cfa46be49fc1083481...</td>\n      <td>0</td>\n      <td>87.944170</td>\n      <td>112.365452</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10128</th>\n      <td>5dc8cea7659e181adb076a3f_fd64de8c4a2fc5ebb0e9f...</td>\n      <td>5</td>\n      <td>208.630347</td>\n      <td>101.163545</td>\n    </tr>\n    <tr>\n      <th>10129</th>\n      <td>5dc8cea7659e181adb076a3f_fd64de8c4a2fc5ebb0e9f...</td>\n      <td>5</td>\n      <td>206.774168</td>\n      <td>103.814537</td>\n    </tr>\n    <tr>\n      <th>10130</th>\n      <td>5dc8cea7659e181adb076a3f_fd64de8c4a2fc5ebb0e9f...</td>\n      <td>5</td>\n      <td>204.091932</td>\n      <td>110.622288</td>\n    </tr>\n    <tr>\n      <th>10131</th>\n      <td>5dc8cea7659e181adb076a3f_fd64de8c4a2fc5ebb0e9f...</td>\n      <td>5</td>\n      <td>196.018451</td>\n      <td>116.925300</td>\n    </tr>\n    <tr>\n      <th>10132</th>\n      <td>5dc8cea7659e181adb076a3f_fd64de8c4a2fc5ebb0e9f...</td>\n      <td>5</td>\n      <td>193.621249</td>\n      <td>120.127632</td>\n    </tr>\n  </tbody>\n</table>\n<p>10133 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# LB4522 = LB4522.reset_index(drop=False)\ndf_emsemble.to_csv('LB4470*08+exp2*02.csv', index=True)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T15:12:47.818224Z","iopub.execute_input":"2021-05-29T15:12:47.818614Z","iopub.status.idle":"2021-05-29T15:12:47.909314Z","shell.execute_reply.started":"2021-05-29T15:12:47.818581Z","shell.execute_reply":"2021-05-29T15:12:47.908281Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# device Leakege 実装パート\nhttps://www.kaggle.com/iwatatakuya/use-leakage-considering-device-id-postprocess\n","metadata":{}},{"cell_type":"code","source":"df_sample = df_emsemble.copy()\n\ndf_sample[\"site_id\"] = df_emsemble[\"site_path_timestamp\"].apply(lambda x:x.split('_')[0])\ndf_sample[\"path_id\"] = df_sample[\"site_path_timestamp\"].apply(lambda x:x.split('_')[1])\ndf_sample[\"timestamp\"] = df_sample[\"site_path_timestamp\"].apply(lambda x:x.split('_')[2]).astype(int)\nlist_site = df_sample[\"site_id\"].unique()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T12:50:55.780938Z","iopub.execute_input":"2021-05-29T12:50:55.781358Z","iopub.status.idle":"2021-05-29T12:50:55.821284Z","shell.execute_reply.started":"2021-05-29T12:50:55.781313Z","shell.execute_reply":"2021-05-29T12:50:55.820306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@dataclass\nclass ReadData:\n    acce: np.ndarray\n    acce_uncali: np.ndarray\n    gyro: np.ndarray\n    gyro_uncali: np.ndarray\n    magn: np.ndarray\n    magn_uncali: np.ndarray\n    ahrs: np.ndarray\n    wifi: np.ndarray\n    ibeacon: np.ndarray\n    waypoint: np.ndarray\n    starttime: int\n    endtime: int\n\ndef read_data_file(data_filename):\n    acce = []\n    acce_uncali = []\n    gyro = []\n    gyro_uncali = []\n    magn = []\n    magn_uncali = []\n    ahrs = []\n    wifi = []\n    ibeacon = []\n    waypoint = []\n    starttime = -1\n    endtime = -1\n\n    with open(data_filename, 'r', encoding='utf-8') as file:\n        lines = file.readlines()\n\n    for line_data in lines:\n        line_data = line_data.strip()\n        if not line_data: continue\n        if len(line_data) > 20: \n            if line_data[2:7] == 'start':\n                if len(line_data.split(':')) > 1: starttime = int(line_data.split(':')[1])\n                else: starttime = int(line_data.split('\\t')[2])\n                continue   \n            if line_data[2:5] == 'end':\n                if len(line_data.split(':')) > 1: endtime = int(line_data.split(':')[1])\n                else: endtime = int(line_data.split('\\t')[2])\n                continue \n\n        if line_data[0] == '#': continue\n\n        line_data = line_data.split('\\t')\n        if line_data[1] == 'TYPE_WAYPOINT':\n            waypoint.append([int(line_data[0]), float(line_data[2]), float(line_data[3])])\n            continue\n       \n        if line_data[1] == 'TYPE_ACCELEROMETER':\n            acce.append([int(line_data[0]), float(line_data[2]), float(line_data[3]), float(line_data[4])])\n            continue\n        \n        if line_data[1] == 'TYPE_ACCELEROMETER_UNCALIBRATED':\n            acce_uncali.append([int(line_data[0]), float(line_data[2]), float(line_data[3]), float(line_data[4])])\n            continue\n        \n        if line_data[1] == 'TYPE_GYROSCOPE':\n            gyro.append([int(line_data[0]), float(line_data[2]), float(line_data[3]), float(line_data[4])])\n            continue\n\n        if line_data[1] == 'TYPE_GYROSCOPE_UNCALIBRATED':\n            gyro_uncali.append([int(line_data[0]), float(line_data[2]), float(line_data[3]), float(line_data[4])])\n            continue\n        \n        if line_data[1] == 'TYPE_MAGNETIC_FIELD':\n            magn.append([int(line_data[0]), float(line_data[2]), float(line_data[3]), float(line_data[4])])\n            continue\n\n        if line_data[1] == 'TYPE_MAGNETIC_FIELD_UNCALIBRATED':\n            if len(line_data) > 7:\n                magn_uncali.append([int(line_data[0]), float(line_data[2]), float(line_data[3]), float(line_data[4]), float(line_data[5]), float(line_data[6]), float(line_data[7])])\n            else:\n                magn_uncali.append([int(line_data[0]), float(line_data[2]), float(line_data[3]), float(line_data[4]), 0, 0, 0])\n            continue\n\n        if line_data[1] == 'TYPE_ROTATION_VECTOR':\n            ahrs.append([int(line_data[0]), float(line_data[2]), float(line_data[3]), float(line_data[4])])\n            continue\n\n        if line_data[1] == 'TYPE_WIFI':\n            sys_ts = line_data[0]\n            ssid = line_data[2]\n            bssid = line_data[3]\n            rssi = line_data[4]\n            lastseen_ts = line_data[6]\n            wifi_data = [sys_ts, ssid, bssid, rssi, lastseen_ts]\n            wifi.append(wifi_data)\n            continue\n\n        if line_data[1] == 'TYPE_BEACON':\n            ts = line_data[0]\n            uuid = line_data[2]\n            major = line_data[3]\n            minor = line_data[4]\n            rssi = line_data[6]\n            dist = line_data[7]\n            last_seen_timestamp = line_data[9]\n            ibeacon_data = [ts, '_'.join([uuid, major, minor]), rssi, dist,last_seen_timestamp]\n            ibeacon.append(ibeacon_data)\n            continue\n        \n    \n    acce = np.array(acce)\n    acce_uncali = np.array(acce_uncali)\n    gyro = np.array(gyro)\n    gyro_uncali = np.array(gyro_uncali)\n    magn = np.array(magn)\n    magn_uncali = np.array(magn_uncali)\n    ahrs = np.array(ahrs)\n    wifi = np.array(wifi)\n    ibeacon = np.array(ibeacon)\n    waypoint = np.array(waypoint)\n    \n    return ReadData(acce, acce_uncali, gyro, gyro_uncali, magn, magn_uncali, ahrs, wifi, ibeacon, waypoint, starttime, endtime)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T12:50:55.823461Z","iopub.execute_input":"2021-05-29T12:50:55.823907Z","iopub.status.idle":"2021-05-29T12:50:55.854632Z","shell.execute_reply.started":"2021-05-29T12:50:55.82386Z","shell.execute_reply":"2021-05-29T12:50:55.853654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_leak = pd.DataFrame()\n\nprint(f'list_site Length : {len(list_site)}')\n\nfor site_id in tqdm(list_site):\n    print(site_id)\n    \n    ## train\n    list_train_files = glob(f\"../input/indoor-location-navigation/train/{site_id}/**/*.txt\", recursive = True)\n    l_pid = []\n    l_sts = []\n    l_ets = []\n    l_swpx = []\n    l_swpy = []\n    l_ewpx = []\n    l_ewpy = []\n    l_d = []\n    for filename in tqdm(list_train_files):\n        path_id = filename.split(\".\")[2].split(\"/\")[6]\n        try: df_all = read_data_file(filename)\n        except:continue\n        \n        # get start and end timestamp\n        sts = df_all.starttime\n        ets = df_all.endtime\n        \n        df_waypoint = pd.DataFrame(df_all.waypoint)\n        df_waypoint.columns = ['timestamp', 'waypoint_x','waypoint_y']\n        df_waypoint[\"timestamp\"] = (df_waypoint[\"timestamp\"]).astype(float)\n        \n        # search start and end waypoints of each path\n        swpx = df_waypoint.query(\"timestamp == @df_waypoint.timestamp.min()\")[\"waypoint_x\"].iloc[0]\n        swpy = df_waypoint.query(\"timestamp == @df_waypoint.timestamp.min()\")[\"waypoint_y\"].iloc[0]\n        ewpx = df_waypoint.query(\"timestamp == @df_waypoint.timestamp.max()\")[\"waypoint_x\"].iloc[0]\n        ewpy = df_waypoint.query(\"timestamp == @df_waypoint.timestamp.max()\")[\"waypoint_y\"].iloc[0]\n\n        # search device id besed on magn bias\n        d = sum(df_all.magn_uncali[0,4:7])\n        if d == 0:d = sum(df_all.magn_uncali[0,1:4] - df_all.magn[0,1:4])\n        d = round(d,2)\n\n        l_pid += [path_id]\n        l_sts += [sts]\n        l_ets += [ets]\n        l_swpx += [swpx]\n        l_swpy += [swpy]\n        l_ewpx += [ewpx]\n        l_ewpy += [ewpy]\n        l_d += [d]        \n    df_mart_train = pd.DataFrame(data={\"path_id\": l_pid,\n                                       \"start_time\": l_sts, \"end_time\": l_ets,\n                                       \"start_waypoint_x\": l_swpx, \"start_waypoint_y\": l_swpy,\n                                       \"end_waypoint_x\": l_ewpx, \"end_waypoint_y\": l_ewpy,\n                                       \"device\": l_d},\n                                 columns=[\"path_id\",\"start_time\",\"end_time\",\"start_waypoint_x\",\"start_waypoint_y\",\n                                          \"end_waypoint_x\", \"end_waypoint_y\", \"device\"])\n\n    l_pid = []\n    l_sts = []\n    l_ets = []\n    l_swpx = []\n    l_swpy = []\n    l_ewpx = []\n    l_ewpy = []\n    l_d = []\n    \n    ## test\n    df_sample_site = df_sample.query(\"site_id == @site_id\")\n    df_sample_site[\"timestamp\"] = df_sample_site[\"timestamp\"].astype(float)\n    list_path = df_sample_site[\"path_id\"].unique()\n    for path_id in tqdm(list_path):\n        df_sample_path = df_sample_site.query(\"path_id == @path_id\")\n        filename = f\"../input/indoor-location-navigation/test/{path_id}.txt\"\n        df_all = read_data_file(filename)\n        df_wifi = pd.DataFrame(df_all.wifi)\n        df_wifi.columns = ['timestamp', 'ssid', 'bssid', 'rssi', 'last_seen_timestamp']\n        df_wifi[\"timestamp\"] = (df_wifi[\"timestamp\"]).astype(float)\n        df_wifi[\"last_seen_timestamp\"] = (df_wifi[\"last_seen_timestamp\"]).astype(float)  \n        \n        df_ibeacon = pd.DataFrame(df_all.ibeacon)\n        # retrieve raw timestamp\n        if len(df_ibeacon) > 0:\n            df_ibeacon.columns = ['timestamp', 'uuid', 'rssi', 'dist','last_seen_timestamp']\n            df_ibeacon[\"timestamp\"] = (df_ibeacon[\"timestamp\"]).astype(float)\n            df_ibeacon[\"last_seen_timestamp\"] = (df_ibeacon[\"last_seen_timestamp\"]).astype(float)\n            time_diff = df_ibeacon.loc[0,\"last_seen_timestamp\"]-df_ibeacon.loc[0,\"timestamp\"]\n        else:\n            time_diff = (df_wifi[\"last_seen_timestamp\"] - df_wifi[\"timestamp\"]).max()\n            \n        # search device id besed on magn bias\n        d = sum(df_all.magn_uncali[0,4:7])\n        if d == 0:d = sum(df_all.magn_uncali[0,1:4] - df_all.magn[0,1:4])\n        d = round(d,2)\n        \n        sts = df_all.starttime + time_diff\n        ets = df_all.endtime + time_diff\n        swpx = np.nan;swpy = np.nan; ewpx = np.nan; ewpy = np.nan;floor = np.nan\n        # x and y\n        df_start = df_mart_train.query(\"device == @d and start_time > @ets - 2000 and start_time < @ets + 10000\").sort_values(\"start_time\").reset_index()\n        df_end = df_mart_train.query(\"device == @d and end_time < @sts + 2000 and end_time > @sts - 10000\").sort_values(\"end_time\",ascending=False).reset_index()\n        if len(df_start) > 0:\n            ewpx = df_start.iloc[0][\"start_waypoint_x\"]\n            ewpy = df_start.iloc[0][\"start_waypoint_y\"]\n        if len(df_end) > 0:\n            swpx = df_end.iloc[0][\"end_waypoint_x\"]\n            swpy = df_end.iloc[0][\"end_waypoint_y\"]\n\n        l_pid += [path_id]\n        l_sts += [sts]\n        l_ets += [ets]\n        l_swpx += [swpx]\n        l_swpy += [swpy]\n        l_ewpx += [ewpx]\n        l_ewpy += [ewpy]\n        l_d += [d]    \n      \n    df_mart_test = pd.DataFrame(data={\"path_id\": l_pid,\n                                       \"start_time\": df_all.starttime, \"end_time\": df_all.endtime,\n                                       \"start_waypoint_x\": l_swpx, \"start_waypoint_y\": l_swpy,\n                                       \"end_waypoint_x\": l_ewpx, \"end_waypoint_y\": l_ewpy,\n                                       \"device\": l_d},\n                                 columns=[\"path_id\",\"start_time\",\"end_time\",\"start_waypoint_x\",\"start_waypoint_y\",\n                                          \"end_waypoint_x\", \"end_waypoint_y\",\"device\"])\n    \n    df_leak = df_leak.append(df_mart_test)\n    \n    # calculate time difference and waypoint difference\n    df_tr = df_mart_train.sort_values([\"device\",\"start_time\"]).reset_index(drop=True)\n    df_tr[\"time_diff\"] = df_tr[\"start_time\"] - df_tr.groupby(\"device\").shift(1)[\"end_time\"]\n    df_tr[\"x_diff\"] = df_tr[\"start_waypoint_x\"] - df_tr.groupby(\"device\").shift(1)[\"end_waypoint_x\"]\n    df_tr[\"y_diff\"] = df_tr[\"start_waypoint_y\"] - df_tr.groupby(\"device\").shift(1)[\"end_waypoint_y\"]\n    \n    print(f'{site_id} : Done')","metadata":{"execution":{"iopub.status.busy":"2021-05-29T12:50:55.856196Z","iopub.execute_input":"2021-05-29T12:50:55.85649Z","iopub.status.idle":"2021-05-29T13:31:13.693652Z","shell.execute_reply.started":"2021-05-29T12:50:55.856462Z","shell.execute_reply":"2021-05-29T13:31:13.692375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_sample","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:42:42.261645Z","iopub.execute_input":"2021-05-29T13:42:42.262311Z","iopub.status.idle":"2021-05-29T13:42:42.285417Z","shell.execute_reply.started":"2021-05-29T13:42:42.262274Z","shell.execute_reply":"2021-05-29T13:42:42.284581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# apply leakage waypoint\ndf_device_leak = df_sample.copy()\nlist_path = df_device_leak[\"path_id\"].unique()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:49:38.521571Z","iopub.execute_input":"2021-05-29T13:49:38.521992Z","iopub.status.idle":"2021-05-29T13:49:38.530395Z","shell.execute_reply.started":"2021-05-29T13:49:38.521954Z","shell.execute_reply":"2021-05-29T13:49:38.529353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfor path_id in tqdm(list_path):\n    df_device_leak_path = df_device_leak.query(\"path_id == @path_id\")\n    start_idx = df_device_leak.loc[df_device_leak[\"path_id\"] == path_id].index.min()\n    end_idx = df_device_leak.loc[df_device_leak[\"path_id\"] == path_id].index.max()\n    start_x = df_device_leak_path.at[start_idx,\"x\"]\n    start_y = df_device_leak_path.at[start_idx,\"y\"]\n    end_x = df_device_leak_path.at[end_idx,\"x\"]\n    end_y = df_device_leak_path.at[end_idx,\"y\"]\n    start_x_leak = df_leak.query(\"path_id == @path_id\")[\"start_waypoint_x\"].iloc[0]\n    start_y_leak = df_leak.query(\"path_id == @path_id\")[\"start_waypoint_y\"].iloc[0]\n    end_x_leak = df_leak.query(\"path_id == @path_id\")[\"end_waypoint_x\"].iloc[0]\n    end_y_leak = df_leak.query(\"path_id == @path_id\")[\"end_waypoint_y\"].iloc[0]\n    if not np.isnan(start_x_leak):\n        df_device_leak.at[start_idx,\"x\"] = start_x_leak\n        df_device_leak.at[start_idx,\"y\"] = start_y_leak\n    if not np.isnan(end_x_leak):\n        df_device_leak.at[end_idx,\"x\"] = end_x_leak\n        df_device_leak.at[end_idx,\"y\"] = end_y_leak","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:49:40.101333Z","iopub.execute_input":"2021-05-29T13:49:40.101713Z","iopub.status.idle":"2021-05-29T13:49:50.89634Z","shell.execute_reply.started":"2021-05-29T13:49:40.101681Z","shell.execute_reply":"2021-05-29T13:49:50.895549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_device_leak.drop([\"site_id\",\"path_id\",\"timestamp\"],axis=1).to_csv(\"LB4470_085_exp2_015_device_leak.csv\",index = False)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:50:18.966219Z","iopub.execute_input":"2021-05-29T13:50:18.966716Z","iopub.status.idle":"2021-05-29T13:50:19.056593Z","shell.execute_reply.started":"2021-05-29T13:50:18.966569Z","shell.execute_reply":"2021-05-29T13:50:19.055518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Snap to Grid パート\nhttps://www.kaggle.com/robikscube/indoor-navigation-snap-to-grid-post-processing","metadata":{}},{"cell_type":"code","source":"def split_col(df):\n    df = pd.concat([\n        df['site_path_timestamp'].str.split('_', expand=True) \\\n        .rename(columns={0:'site',\n                         1:'path',\n                         2:'timestamp'}),\n        df\n    ], axis=1).copy()\n    return df\n\nfloor_map = {\"B2\":-2, \"B1\":-1, \"F1\":0, \"F2\": 1, \"F3\":2,\n             \"F4\":3, \"F5\":4, \"F6\":5, \"F7\":6,\"F8\":7,\"F9\":8,\n             \"1F\":0, \"2F\":1, \"3F\":2, \"4F\":3, \"5F\":4, \"6F\":5,\n             \"7F\":6, \"8F\": 7, \"9F\":8}\n\n\ndef plot_preds(\n    site,\n    floorNo,\n    sub=None,\n    true_locs=None,\n    base=\"../input/indoor-location-navigation\",\n    show_train=True,\n    show_preds=True,\n    fix_labels=True,\n    map_floor=None\n):\n    \"\"\"\n    Plots predictions on floorplan map.\n    \n    map_floor : use a different floor's map\n    \"\"\"\n    if map_floor is None:\n        map_floor = floorNo\n    # Prepare width_meter & height_meter (taken from the .json file)\n    floor_plan_filename = f\"{base}/metadata/{site}/{map_floor}/floor_image.png\"\n    json_plan_filename = f\"{base}/metadata/{site}/{map_floor}/floor_info.json\"\n    with open(json_plan_filename) as json_file:\n        json_data = json.load(json_file)\n\n    width_meter = json_data[\"map_info\"][\"width\"]\n    height_meter = json_data[\"map_info\"][\"height\"]\n\n    floor_img = plt.imread(f\"{base}/metadata/{site}/{map_floor}/floor_image.png\")\n\n    fig, ax = plt.subplots(figsize=(12, 12))\n    plt.imshow(floor_img)\n\n    if show_train:\n        true_locs = true_locs.query('site == @site and floorNo == @map_floor').copy()\n        true_locs[\"x_\"] = true_locs[\"x\"] * floor_img.shape[0] / height_meter\n        true_locs[\"y_\"] = (\n            true_locs[\"y\"] * -1 * floor_img.shape[1] / width_meter\n        ) + floor_img.shape[0]\n        true_locs.query(\"site == @site and floorNo == @map_floor\").groupby(\"path\").plot(\n            x=\"x_\",\n            y=\"y_\",\n            style=\"+\",\n            ax=ax,\n            label=\"train waypoint location\",\n            color=\"grey\",\n            alpha=0.5,\n        )\n\n    if show_preds:\n        sub = sub.query('site == @site and floorNo == @floorNo').copy()\n        sub[\"x_\"] = sub[\"x\"] * floor_img.shape[0] / height_meter\n        sub[\"y_\"] = (\n            sub[\"y\"] * -1 * floor_img.shape[1] / width_meter\n        ) + floor_img.shape[0]\n        for path, path_data in sub.query(\n            \"site == @site and floorNo == @floorNo\"\n        ).groupby(\"path\"):\n            path_data.plot(\n                x=\"x_\",\n                y=\"y_\",\n                style=\".-\",\n                ax=ax,\n                title=f\"{site} - floor - {floorNo}\",\n                alpha=1,\n                label=path,\n            )\n    if fix_labels:\n        handles, labels = ax.get_legend_handles_labels()\n        by_label = dict(zip(labels, handles))\n        plt.legend(\n            by_label.values(), by_label.keys(), loc=\"center left\", bbox_to_anchor=(1, 0.5)\n        )\n    return fig, ax\n\ndef sub_process(sub, train_waypoints):\n    train_waypoints['isTrainWaypoint'] = True\n    sub = split_col(sub[['site_path_timestamp','floor','x','y']]).copy()\n    sub = sub.merge(train_waypoints[['site','floorNo','floor']].drop_duplicates(), how='left')\n    sub = sub.merge(\n        train_waypoints[['x','y','site','floor','isTrainWaypoint']].drop_duplicates(),\n        how='left',\n        on=['site','x','y','floor']\n             )\n    sub['isTrainWaypoint'] = sub['isTrainWaypoint'].fillna(False)\n    return sub.copy()\n\n\ndef plot_hist(sub):\n    sub['dist_pp_change'] = np.sqrt(((sub['x'] - sub['_x_']) ** 2) + ((sub['y'] - sub['_y_']) ** 2))\n    fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n    sub['dist_pp_change'].plot(kind='hist', bins=30,\n                               ax=axs[0],\n                               title='Distance Changed by Post Processing')\n    sub.query('dist_pp_change > 0.1')['dist_pp_change'] \\\n        .plot(kind='hist', bins=30, ax=axs[1],\n              title='Distance Changed (Excluding <0.1 Change)')\n    \n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:56:10.194476Z","iopub.execute_input":"2021-05-29T13:56:10.194871Z","iopub.status.idle":"2021-05-29T13:56:10.220547Z","shell.execute_reply.started":"2021-05-29T13:56:10.194835Z","shell.execute_reply":"2021-05-29T13:56:10.219685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sub = pd.read_csv('../input/indoor-emsemble/LB4470_09_exp2_01_device_leak.csv')\n\ntrain_waypoints = pd.read_csv('../input/indoor-location-train-waypoints/train_waypoints.csv')\n# sub = sub_process(pd.read_csv('../input/indoor-location-train-waypoints/6.578LB_submission.csv'),\n#                  train_waypoints)\nsub = sub_process(df_device_leak, train_waypoints)\n# Plot the training Data For an example Floor\nexample_site = '5dbc1d84c1eb61796cf7c010'\nexample_floorNo = 'F3'\n\nplot_preds(example_site, example_floorNo, sub,\n           train_waypoints, show_preds=False)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:56:13.570539Z","iopub.execute_input":"2021-05-29T13:56:13.570956Z","iopub.status.idle":"2021-05-29T13:56:21.082576Z","shell.execute_reply.started":"2021-05-29T13:56:13.570918Z","shell.execute_reply":"2021-05-29T13:56:21.079564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy.spatial.distance import cdist\n\ndef add_xy(df):\n    df['xy'] = [(x, y) for x,y in zip(df['x'], df['y'])]\n    return df\n\ndef closest_point(point, points):\n    \"\"\" Find closest point from a list of points. \"\"\"\n    return points[cdist([point], points).argmin()]\n\nsub = add_xy(sub)\ntrain_waypoints = add_xy(train_waypoints)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:56:25.352397Z","iopub.execute_input":"2021-05-29T13:56:25.352753Z","iopub.status.idle":"2021-05-29T13:56:25.610069Z","shell.execute_reply.started":"2021-05-29T13:56:25.35272Z","shell.execute_reply":"2021-05-29T13:56:25.608968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds = []\nfor (site, myfloor), d in sub.groupby(['site','floor']):\n    true_floor_locs = train_waypoints.loc[(train_waypoints['floor'] == myfloor) &\n                                          (train_waypoints['site'] == site)] \\\n        .reset_index(drop=True)\n    if len(true_floor_locs) == 0:\n        print(f'Skipping {site} {myfloor}')\n        continue\n    d['matched_point'] = [closest_point(x, list(true_floor_locs['xy'])) for x in d['xy']]\n    d['x_'] = d['matched_point'].apply(lambda x: x[0])\n    d['y_'] = d['matched_point'].apply(lambda x: x[1])\n    ds.append(d)\n\nsub = pd.concat(ds)\n\n# Example of raw predictions\nplot_preds(example_site, example_floorNo, sub,\n           train_waypoints, show_preds=True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:56:25.772097Z","iopub.execute_input":"2021-05-29T13:56:25.772434Z","iopub.status.idle":"2021-05-29T13:56:46.533761Z","shell.execute_reply.started":"2021-05-29T13:56:25.772405Z","shell.execute_reply":"2021-05-29T13:56:46.532608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"th = 4\n\nsub_th4 = sub.copy()\n\ndef snap_to_grid(sub, threshold):\n    \"\"\"\n    Snap to grid if within a threshold.\n    \n    x, y are the predicted points.\n    x_, y_ are the closest grid points.\n    _x_, _y_ are the new predictions after post processing.\n    \"\"\"\n    sub['_x_'] = sub['x']\n    sub['_y_'] = sub['y']\n    sub.loc[sub['dist'] < threshold, '_x_'] = sub.loc[sub['dist'] < threshold]['x_']\n    sub.loc[sub['dist'] < threshold, '_y_'] = sub.loc[sub['dist'] < threshold]['y_']\n    return sub.copy()\n\n# Calculate the distances\nsub_th4['dist'] = np.sqrt( (sub_th4.x-sub_th4.x_)**2 + (sub_th4.y-sub_th4.y_)**2 )\n\nsub_pp_th4= snap_to_grid(sub_th4, threshold = th)\n\nsub_pp_th4 = sub_pp_th4[['site_path_timestamp','floor','_x_','_y_','site','path','floorNo']] \\\n    .rename(columns={'_x_':'x', '_y_':'y'})\n\n# Plot example after post processing\nplot_preds(example_site, example_floorNo, sub_pp_th4,\n           train_waypoints, show_preds=True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:56:46.535895Z","iopub.execute_input":"2021-05-29T13:56:46.536327Z","iopub.status.idle":"2021-05-29T13:56:54.697173Z","shell.execute_reply.started":"2021-05-29T13:56:46.536284Z","shell.execute_reply":"2021-05-29T13:56:54.696239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axs = plt.subplots(1, 1, figsize=(5, 5))\n\nsub_th4['dist'].plot(kind='hist', bins=30,title='Distance Changed by Post Processing')","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:56:54.698569Z","iopub.execute_input":"2021-05-29T13:56:54.699152Z","iopub.status.idle":"2021-05-29T13:56:54.894267Z","shell.execute_reply.started":"2021-05-29T13:56:54.699096Z","shell.execute_reply":"2021-05-29T13:56:54.893201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_hist(sub_th4)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T14:15:44.998584Z","iopub.execute_input":"2021-05-29T14:15:44.99908Z","iopub.status.idle":"2021-05-29T14:15:45.42901Z","shell.execute_reply.started":"2021-05-29T14:15:44.999046Z","shell.execute_reply":"2021-05-29T14:15:45.428234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_pp_th4[['site_path_timestamp','floor','x','y']] \\\n    .to_csv('LB4470_08_exp2_02_thresh4_snap_to_grid.csv', index=False)\n# /LB4470_0.95exp2_0.05_device_leak","metadata":{"execution":{"iopub.status.busy":"2021-05-29T14:30:14.295283Z","iopub.execute_input":"2021-05-29T14:30:14.295724Z","iopub.status.idle":"2021-05-29T14:30:14.372712Z","shell.execute_reply.started":"2021-05-29T14:30:14.295691Z","shell.execute_reply":"2021-05-29T14:30:14.37196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}